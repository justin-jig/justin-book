---
title: "CUDA 및 NVIDIA 통합 설정 (CUDA Integration with Docker)"
date: 2025-10-23
---

#### 요약  
Docker에서 GPU를 사용하려면 **NVIDIA 드라이버**, **CUDA Toolkit**,  
**Container Toolkit** 세 가지 요소가 올바르게 설치되어야 한다.  
이후 `--gpus all` 플래그로 GPU 연동 컨테이너를 실행할 수 있다.  


* CUDA Toolkit + Container Toolkit 조합으로 GPU 사용 가능.
* `nvidia-smi` 로 컨테이너 내부 GPU 접근 여부 확인.
* Compose와 Kubernetes 모두 `--gpus` 혹은 `device` 기반 할당을 지원한다.


**핵심 정리**
- NVIDIA Container Toolkit은 Docker와 CUDA 런타임을 연결한다.  
- 호스트의 GPU 드라이버 버전은 CUDA와 반드시 호환되어야 한다.  
- `nvidia-smi` 명령으로 컨테이너 내부 GPU 접근 여부를 확인한다.  

##### 참고자료
- [NVIDIA Container Toolkit Installation Guide](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html)
- [CUDA Compatibility Table](https://docs.nvidia.com/deploy/cuda-compatibility/)
- [Docker GPU Reference](https://docs.docker.com/config/containers/resource_constraints/#gpu)

---

#### 1. 설치 순서 요약

| 단계 | 구성 요소 | 설명 |
|:--|:--|:--|
| 1 | NVIDIA 드라이버 | GPU 장치 제어용 커널 모듈 |
| 2 | CUDA Toolkit | GPU 연산 및 라이브러리 제공 |
| 3 | Docker | 컨테이너 런타임 |
| 4 | NVIDIA Container Toolkit | Docker와 GPU 연동 |

---

#### 2. 설치 명령 예시 (Ubuntu 22.04 기준)
```bash
# 1. 드라이버 설치
sudo apt install -y nvidia-driver-550

# 2. CUDA Toolkit 설치
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-repo.deb
sudo dpkg -i cuda-repo.deb && sudo apt update && sudo apt install -y cuda-toolkit-12-4

# 3. NVIDIA Container Toolkit 설치
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/libnvidia-container/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
sudo apt update && sudo apt install -y nvidia-container-toolkit
```

---

#### 3. Docker 런타임 구성 확인

```bash
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker
```

> Docker가 GPU 장치를 인식하도록 런타임을 재설정한다.

---

#### 4. 테스트

```bash
docker run --rm --gpus all nvidia/cuda:12.4.0-base nvidia-smi
```

출력 예시:

```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 550.76   Driver Version: 550.76   CUDA Version: 12.4             |
+-----------------------------------------------------------------------------+
```

> GPU 정보가 출력되면 설정이 정상적으로 완료된 것이다.

---

#### 5. Compose 연동 예시

```yaml
services:
  trainer:
    image: pytorch/pytorch:2.2.0-cuda12.1-cudnn8-runtime
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
```

> Compose 파일에서 GPU 자원을 선언적으로 예약할 수 있다.

---

