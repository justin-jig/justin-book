---
title: "GPU 및 하드웨어 가속기 개요 (GPU and Accelerators Overview)"
date: 2025-10-23
---

#### 요약  
Docker는 CPU 이외에도 GPU, TPU, FPGA 등의 하드웨어 가속기를 컨테이너 내에서 활용할 수 있다.  
특히 **NVIDIA Container Toolkit** 을 사용하면 GPU를 Docker 런타임에 직접 통합할 수 있다.  
이 기능은 AI, ML, 딥러닝, 영상 처리 등 고성능 연산 워크로드에 필수적이다.  


* NVIDIA Container Toolkit으로 GPU를 Docker에 통합 가능.
* `--gpus` 옵션으로 유연한 자원 제어 가능.
* GPU 외에도 TPU/FPGA 등 다양한 가속기 통합이 가능하다.

**핵심 정리**
- GPU 자원을 컨테이너에 안전하게 할당할 수 있다.  
- NVIDIA Container Toolkit으로 CUDA 런타임을 자동 관리.  
- `--gpus` 옵션으로 GPU 사용 범위를 지정 가능.  
- Multi-GPU 환경에서 특정 GPU를 선택적으로 할당할 수 있다.  

##### 참고자료
- [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/)
- [Docker Docs – GPU Support](https://docs.docker.com/config/containers/resource_constraints/#gpu)
- [CUDA Toolkit Documentation](https://developer.nvidia.com/cuda-toolkit)

---

#### 1. GPU 지원 전제조건

| 구성요소 | 설명 |
|:--|:--|
| NVIDIA 드라이버 | 호스트 OS에 설치 (CUDA 버전 호환 필수) |
| CUDA Toolkit | GPU 런타임 및 라이브러리 |
| NVIDIA Container Toolkit | Docker와 GPU 연동 플러그인 |
| Docker 19.03+ | `--gpus` 플래그 지원 버전 이상 필요 |

---

#### 2. GPU 활성화 예시

```bash
docker run --rm --gpus all nvidia/cuda:12.3.2-base nvidia-smi
```

> 컨테이너 내에서 GPU 장치 정보를 출력하면 정상 동작을 확인할 수 있다.

---

#### 3. 특정 GPU만 할당

```bash
docker run --gpus '"device=0,1"' pytorch/pytorch:latest
```

> `device` 인덱스로 특정 GPU를 선택할 수 있다.

---

#### 4. Multi-GPU 모니터링

```bash
watch -n 2 nvidia-smi
```

> GPU 메모리, 사용률, 프로세스 정보를 실시간으로 확인한다.

---

#### 5. 기타 하드웨어 가속기

| 가속기      | 주요 용도                 | Docker 통합 방식          |
| :------- | :-------------------- | :-------------------- |
| **TPU**  | TensorFlow, Vertex AI | 클라우드 API 연동           |
| **FPGA** | 데이터 변환, 엣지 컴퓨팅        | Xilinx Docker Runtime |
| **ASIC** | 영상 처리, 암호화            | 제조사 SDK 기반            |

---
